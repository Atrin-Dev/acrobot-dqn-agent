# Deep Q-Learning for Acrobot-v1

## ğŸš€ Introduction
This repository implements **Deep Q-Learning (DQN)** for training an agent to solve the *Acrobot-v1* environment from OpenAI Gymnasium.

## ğŸ“Œ Features
- **Implements Deep Q-Network (DQN) with Experience Replay**
- **Uses PyTorch for neural network training**
- **Supports GPU acceleration (if available)**
- **Provides visualization of the trained agent**

## ğŸ“‚ Project Structure
```plaintext
dqn-acrobot-v1
â”‚â”€â”€ ğŸ“œ README.md           # Project documentation
â”‚â”€â”€ ğŸ“œ requirements.txt     # Dependencies
â”‚â”€â”€ ğŸ“œ train.py            # Training script
â”‚â”€â”€ ğŸ“œ test.py             # Evaluation script
â”‚â”€â”€ ğŸ“œ model.py            # Neural network architecture
â”‚â”€â”€ ğŸ“œ agent.py            # DQN agent implementation
â”‚â”€â”€ ğŸ“œ replay_buffer.py    # Experience replay buffer
â”‚â”€â”€ ğŸ“œ environment.py      # Gym environment setup
â”‚â”€â”€ ğŸ“œ visualize.py        # Video visualization script
```
###  Install Dependencies
```bash
pip install -r requirements.txt
```
### ğŸ® Training the agent
Run the following command to train the DQN agent:
```bash
python train.py --episodes 3000 --timesteps 1500 --epsilon_start 1.0 --epsilon_end 0.05 --epsilon_decay 0.99 --model_path "trained_model.pth"
```
This will train the agent in the Acrobot-v1 environment and save the model checkpoint if the agent solves the environment.
### ğŸ“Š Visualizing the trained agent
To visualize the trained agent, run:
```bash
python script.py --visualize --model_path checkpoint.pth --video_path video.mp4
```
This will generate a video of the agent interacting with the environment.

### ğŸ“Š Visualizing the Results
[Watch the trained agent by clicking the link](https://github.com/Atrin-Dev/acrobot-dqn-agent/blob/main/Acrobot.gif)
![Demo](https://github.com/Atrin-Dev/acrobot-dqn-agent/blob/main/Acrobot.gif)

### ğŸ“ Configuration

You can modify the hyperparameters in main.py:
```
learning_rate = 5e-4
batch_size = 100
discount_factor = 0.99
memory_size = int(1e5)
target_update_rate = 1e-3
```
### ğŸ“¢ Contributing

Contributions are welcome! Feel free to open an issue or submit a pull request.
